\documentclass[letterpaper,titlepage]{article}
\pdfminorversion=4
\usepackage{setspace}
\doublespacing
\usepackage{ dsfont }
\usepackage{amsthm,amsmath,amssymb,natbib}
\RequirePackage[colorlinks,citecolor=blue,urlcolor=blue]{hyperref}

\usepackage{xspace,soul}
\usepackage{graphicx}



\newcommand{\Ex}{\mathbb{E}}
\newcommand{\Var}{\text{Var}}
\newcommand{\bp}{\mathbf{p}}

\newcommand{\R}{\textsf{R}\xspace}
\newcommand{\pkg}[1]{\texttt{#1}\xspace}

\newcommand{\greg}[1]{\sethlcolor{yellow}\hl{[GM]: #1}}
\newcommand{\ben}[1]{\sethlcolor{green}\hl{[BB]: #1}}
\newcommand{\mike}[1]{\sethlcolor{cyan}\hl{[ML]: #1}}

\def\balpha{\pmb{\alpha}}
\def\bbeta{\pmb{\beta}}
\def\bgamma{\pmb{\gamma}}
\def\btheta{\pmb{\theta}}
\def\bphi{\pmb{\phi}}
\def\bpsi{\pmb{\psi}}
\def\bB{\pmb{B}}
\def\bD{\pmb{D}}
\def\bH{\pmb{H}}
\def\bS{\pmb{S}}
\def\bX{\pmb{X}}

\textwidth = 6in
\textheight = 9in

\oddsidemargin = +0.3in

\evensidemargin = +0.3in

\parindent 0pt

\parskip 10pt

\topmargin = -1.5cm


\begin{document}
%\SweaveOpts{concordance=TRUE}
%\SweaveOpts{concordance=TRUE}

\title{How often does the best team win? A unified approach
to understanding randomness in North American sport}
%
\author{
Benjamin S. Baumer \\
%Department of Mathematics \& Statistics \\
Smith College \\
%Northampton, MA 01063, USA \\
\texttt{bbaumer@smith.edu}
\and
Michael Lopez\\
%Department of Statistics \\ 
Skidmore College\\
\texttt{mlopez1@skidmore.edu}
\and
Gregory J. Matthews\\
Loyola University Chicago\\
\texttt{gmatthews1@luc.edu}
}

<<echo=FALSE>>=
source("config.R")
@


\maketitle

\begin{abstract}

Statistical applications in sports have long centered on how to best separate signal, such as team talent, from random noise. However, most of this work has concentrated on a single sport. The development of meaningful cross-sport comparisons has been impeded by the difficulty of translating luck from one sport to another. Building on \cite{glickman1998state}, we present a modified Bayesian state-space approach that provides a uniform understanding of league-level differences in team talent and their evolution. Formally, we use game-level probability information provided by betting markets to estimate team strengths across ten seasons of play in each of the National Football League (NFL), National Hockey League (NHL), National Basketball Association (NBA), and Major League Baseball (MLB). This model captures differences in between-season, within-season, and game-to-game variability of team strengths, as well each team's home advantage. We find that the NBA demonstrates both the largest dispersion in talent and the largest home advantage among the four leagues, while the NHL and MLB stand out for their relative randomness in game outcomes. We conclude by proposing a new metric for judging league parity that works in absence of factors outside of team control. 

Keywords: sports analytics, randomness, Bayesian modeling, competitive balance, MCMC
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\input{intro}

\section{Introduction}
Most observers of sport can agree that game outcomes are to some extent subject to chance. The line drive that miraculously finds the fielder's glove, the fumble that bounces harmlessly out-of-bounds, the puck that ricochets into the net off of an opponent's skate, or the referee's whistle on a clean block can all mean the difference between winning and losing. Yet game outcomes are not \emph{completely} random---there are teams that consistently play better and worse. To what extent does luck influence our perceptions of team strength over time?

One way in which statistics can lead this discussion lies in the untangling of signal and noise when comparing the caliber of each league's teams. For example, is team $i$ better than team $j$? And if so, how confident are we in making this claim? Central to such an understanding of sporting outcomes is that if we know each team's relative strength, then, \textit{a priori}, game outcomes---including wins and losses---can be viewed as unobserved realizations of random variables. As a simple example, a 75\% probability of team $i$ beating team $j$ at time $k$ implies that in a hypothetical infinite number of games between the two teams at time $k$, $i$ wins three times as often as $j$. 

Given both national public interest and an academic curiosity that has extended across disciplines, many innovative techniques have been developed to estimate team strength. These approaches typically blend past game scores with game, team, and player characteristics in a statistical model. Corresponding estimates of talent are often checked or calibrated by comparing out-of-sample estimated probabilities of wins and losses to observed outcomes. Such exercises do more than drive water-cooler conversation as to which team may be better. Indeed, estimating team rankings has driven the development of advanced statistical models \citep{bradley1952rank, glickman1998state} and occasionally played a role in the decision of which teams are eligible for continued postseason play \citep{BCS}. 

However, because randomness manifests differently in different sports, a limitation of sport-specific models is that inferences cannot generally be applied to other competitions. As a result,  researchers who hope to contrast one league to another often focus on the one outcome common to all sports: won-loss ratio. Among other flaws, measuring team strength using wins and losses performs poorly in a small sample size, ignores the game's final score (which is known to be more predictive of future performance than won-loss ratio \citep{boulier2003predicting}), and is unduly impacted by, among other sources, fluctuations in league scheduling, season length, injury to key players, and the general advantage of playing at home. As a result, until now, analysts and fans have never quite been able to quantify inherent differences between sports with respect to randomness and the dispersion and evolution of team strength. We aim to fill this void. 

In the sections that follow, we present a novel approach for estimating team ability that accounts for league scheduling differences, measures each team's home advantage, and uncovers inherent differences in North American sport. First, we validate an assumption that game-level probabilities provided by betting markets provide unbiased and low-variance estimates of the true probabilities of wins and losses in each professional contest. Second, we implement a modified Bayesian state-space model that uses these probabilities to capture implied team strength and variability. Next, by examining posterior estimates of within and between season variability, as well as the overall dispersion in team strength estimates, we present unique league-level contrasts that to this point have been difficult to capture. Finally, we conclude by showing that our estimates of team strength improve upon both won-loss ratio and point differential with respect to correlating to future performance, and use our posterior draws propose a novel metric of assessing parity.  We find that, on account of both narrower talent distributions and smaller home advantages, a typical contest in the NHL or MLB is much closer to a coin-flip than one in the NBA or NFL. Additionally, the NHL (from one season to the next) and NBA (from one week to the next) boast the least consistency in team strength estimates over time.

\subsection{Review}

The importance of quantifying team strength in sport extends across disciplines. This includes contrasting league-level characteristics in economics \citep{leeds2004economics}, estimating game-level probabilities in statistics \citep{glickman1998state}, and classifying future game winners in forecasting \citep{boulier2003predicting}. We discuss and synthesize a few general approaches below.

\subsection{Competitive Balance}

Assessing the competitive balance of sports leagues is particularly important in economics and management \citep{leeds2004economics}. While competitive balance can purportedly measure several different quantities, in general it refers to levels of equivalence between teams. This could be equivalence within one time frame (e.g. how similar was the distribution of talent within a season?), between time frames (e.g. year-to-year variations in talent), or from the beginning of a time frame until the end (e.g. the likelihood of each team winning a championship at the start of a season).

\mike{I removed Gini coefficient. It was disproved as far back as 2002 as far as its relevance.}\ben{Fine with me.}

The most widely accepted within-season competitive balance measure is the Noll-Scully \citep{noll1988professional, scully1989business}, computed as the ratio of the observed standard deviation in team win totals to the idealized standard deviation, defined as that which would have been observed due to chance alone if each team were equal in talent. Larger Noll-Scully values are believed to reflect greater imbalance in team strengths. 

While Noll-Scully has the positive quality of allowing for interpretable cross-sport comparisons, a reliance on won-loss outcomes entails undesireable properties as well \citep{owen2010limitations, owen2015competitive}. For example, Noll-Scully increases, on average, with the number of games played \citep{owen2015competitive}, hindering any comparisons of the NFL (16 games) to MLB (162). Additionally, each of the leagues employ some form of an unbalanced schedule. Teams in each of MLB, the NBA, NFL, and NHL play intradivisional opponents more often than interdivisional ones, and intraconference opponents more often than interconference ones, meaning that one team's won-loss record may not be comparable to another team's due to differences in the respective strengths of their opponents \citep{lenten2015measurement}. Moreover, the NFL structures each season's schedule so that teams play interdivisional games against opponents that finished in the same spot in the standings in the prior year. In expectation, this punishes teams that finish atop standings with tougher games, potentially driving winning percentages toward 0.500. Unsurprisingly, unbalanced scheduling and interconference play can lead to imprecise competitive balance metrics derived from winning percentages \citep{utt2002pitfalls}. As one final weakness, varying home advantages between sports leagues, as shown in \cite{moskowitz2011scorecasting} could also impact comparisons of relative team quality predicated on wins and losses. 

Although metrics for league-level comparisons have been frequently debated, the importance of competitive balance in sports is more uniformly accepted, in large part due to the uncertainty of outcome hypothesis \citep{rottenberg1956baseball, knowles1992demand, lee2008attendance}. Under the uncertainty of outcome hypothesis, league success---as judged by attendance, engagement, and television revenue---correlates positively with teams having equal chances. Outcome uncertainty is generally considered on a game-level basis, but can also extend to season-level success (i.e, teams having equivalent chances at making the postseason). As a result, it is in each league's best interest to promote some level of \emph{parity}---in short, a narrower distribution of team quality---to maximize revenue \citep{crooker2007sports}. Related, the Hirfindahl-Hirschman Index \citep{owen2007measuring} and Competitive Balance Ratio \citep{humphreys2002alternative} are two metrics attempting to quantify the relative chances of success that teams have within or between certain time frames. 

 \subsection{Approaches to estimating team strength}

Competitive balance and outcome uncertainty are rough proxies for understanding the distribution of talent among teams. For example, when two teams of equal talent play a game without a home advantage, outcome uncertainty is maximized; e.g., the outcome of the game is equivalent to a coin flip. These relative comparisons of team talent began in statistics with paired comparison models, which are generally defined as those designed to calibrate the equivalence of two entities. In the case of sports, the entities are teams or individual athletes.

The Bradley-Terry model (BTM, \cite{bradley1952rank}) is considered to be the first detailed paired comparison model, and the rough equivalent of the soon thereafter developed Elo rankings \citep{elo1978rating, glickman1995comprehensive}. Consider an experiment with $t$ treatment levels, compared in pairs. BTM assumes that there is some true ordering of the probabilities of efficacy $\pi_{1}, \ldots, \pi_{t}$ with the constraints that $\pi_{i}\geq 0$ and $\sum\pi_{i} = 1$.  When comparing treatment $i$ to treatment $j$, the probability that treatment $i$ is preferable to $j$ (i.e. a win in a sports setting) is computed as $\frac{\pi_{i}}{\pi_i+\pi_j}$. 

\cite{glickman1998state} and \cite{glickman2016estimating} build on the BTM by allowing team-strength estimates to vary over time through the modeling of point differential in the NFL, which is assumed to follow an approximately normal distribution.  Let $y_{(s,k)ij}$ be the point differential of a game during week $k$ of season $s$ between teams $i$ and $j$. In this specification, $i$ and $j$ take on values between $1$ and $t$, where $t$ is the number of teams in the league. Let $\theta_{(s,k)i}$ and $\theta_{(s,k)j}$ be the strengths of teams $i$ and $j$, respectively, in season $s$ during week $k$, and let $\alpha_i$ be the home advantage parameter for team $i$, for $i = 1,\ldots, t$. \cite{glickman1998state} assumed that for a game played at the home of team $i$ during week $k$ in season $s$,  

$$
E[y_{(s,k)ij}] = \theta_{(s,k)i} - \theta_{(s,k)j} + \alpha_i,
$$

\mike{Should this be a conditional expectation?} \ben{it's obviously conditional on the two thetas and alpha, right?} \mike{That's my thought. Greg can you tweak this?}

where $E[y_{(s,k)ij}]$ is the expected point differential given $i$ and $j$'s team strengths and the home advantage of team $i$.


%The distribution of the outcomes of games during season $s$ and week $k$ is:

%$$
%\bf{y}_{(s,k)}|\tilde{X}_{(s,k)}, \tilde{\theta}_{(s,k)},\phi \sim N(\tilde{X}_{(s,k)}\tilde{\theta}_{(s,k)}, \phi^{-1}I_{n_{(s,k)}}),
%$$


%where $\bf{y}_{(s,k)}$ is a vector of score differentials, $\tilde{\theta}_{(s,k)}$ is a vector containing the team strengths and the home advantage parameters, $\phi$ is the precision, and $n_{(s,k)}$ is the number of games played in week $k$ during season $s$.  The matrix $\tilde{X}_{(s,k)}$ consists of $n_{(s,k)}$ rows and $2t$ columns.  The first $t$ columns contain the values $\{1, 0, -1\}$ where a 1/-1 in the $i^{th}$ column indicates that team $i$ was the home/away team for the game corresponding to that row and a $0$ otherwise.  The second set of $t$ columns (i.e. $t+1$ to $2t$) contains a 1 in the $i^{th}$ column (i.e column $t+i$) if team $i$ is playing at home and 0 otherwise.  

%The model of \cite{glickman1998state} allows for team strength parameters to vary stochastically in two distinct ways: 1) from the last week of season $s$ to the first week of season $s+1$, and 2) from week $k$ of season $s$ to week $k+1$ of season $s$.  

%The variation from the last week of one season to the first week of the next season is expressed as: 

%$$
%\theta_{(s+1,1)} | \gamma_{seas}, \bf{\theta_{(s,g_{s})}}, \phi, \omega_{seas} \sim N (\gamma_{seas}\bf{G}\bf{\theta_{(s,g_{s})}},(\phi\omega_{seas})^{-1}I_{t})
%$$

%where $\bf{G}$ is the matrix that transforms $\bf{\theta_{(s,g_{s})}}$ to $\bf{\theta_{(s,g_{s})}} - \bar{\bf{\theta}}_{(s,g_{s})}$ and $g_{s}$ is the number of weeks in season $s$.  

%Team strength parameters also vary from week-to-week as follows: 
%$$
%\theta_{(s,k+1)} | \gamma_{week}, \bf{\theta}_{(s,k)}, \phi, \omega_{week} \sim N (\gamma_{week}\bf{G}\bf{\theta}_{(s,k)},(\phi\omega_{week})^{-1}I_{t})
%$$

%$Y_{ij}$ is the number of times that team $i$ beats team $j$ and $p_{ij}$ is the probability that team $i$ beats team $j$.  

%$$
%Y_{ij}\sim B(n_{ij},p_{ij})
%$$

%$$
%logit(p_{ij}) = \beta_{i} - \beta_{j}
%$$

The model of \cite{glickman1998state} allows for team strength parameters to vary stochastically in two distinct ways: from the last week of season $s$ to the first week of season $s+1$, and from week $k$ of season $s$ to week $k+1$ of season $s$. As such, it is termed a `state-space' model, whereby the data is a function of an underlying time-varying process plus additional noise. 

\cite{glickman1998state} propose an autoregressive process to team strengths, whereby over time, these estimates are pulled toward the league average. One attractive property of this specification is that past and future season performances are incorporated into season-specific estimates of team quality. Perhaps as a result, \cite{koopmeiners2012comparison} identifies stronger fits when comparing state-space models to BTM's fit separately within each season. Additionally, state-space models would not typically suffer from identifiability problems were a team to win or lose all of its games in a single season (a rare, but extant possibility in the NFL).\footnote{In the NFL, the 2007 New England Patriots won all of their regular season games, while the 2008 Detroit Lions lost all of their regular season games.} For additional and related state-space resources, see \cite{knorr2000dynamic},  \cite{cattelan2013dynamic}, \cite{baker2015time}, and \cite{manner2015modeling}. Additionally, \cite{matthews2005improving}, \cite{owen2011dynamic}, \cite{koopmeiners2012comparison}, \cite{tutz2015extended}, and \cite{wolfson2015s} implement related versions of the original BTM. 

Although the state-space model summarized above appears to work well in the NFL, a few issues arise when extending it to other leagues. First, with point differential as a game-level outcome, parameters would be sensitive to the relative amount of scoring in each sport. Thus, comparisons of the NHL and MLB (where games, on average, are decided by a few goals or runs) to the NBA and NFL (where games, on average, are decided by about 10 points) would require further scaling. Second, it is unclear if a model of goal or run differential is appropriate in low scoring sports like the NHL and MLB. Finally, NHL game outcomes would entail an extra complication, as roughly 25\% of regular season games are decided in overtime or a shootout.

\mike{I added the above paragraph to clarify why exactly we can't just use Glickman's in other sports. There are probably other reasons, too. Feel free to add.} \ben{I like it!}

In place of paired comparison models, alternative measures for estimating team strength have also been developed. \cite{massey1997statistical} used maximum likelihood estimation and American football outcomes to develop an eponymous rating system. A more general summary of other rating systems for forecasting use is explored by \cite{boulier2003predicting}. In addition, support vector machines and simulation models have been proposed in hockey \citep{demers2015riding, buttrey2016beating}, neural networks and na\"{\i}ve Bayes implemented in basketball \citep{loeffelholz2009predicting, miljkovic2010use}, linear models and probit regressions in football \citep{harville1980predictions, boulier2003predicting}, and two stage Bayesian models in baseball \citep{yang2004two}. While this is a non-exhaustive list, it speaks to the depth and variety of coverage that sports prediction models have generated. 


%Alternative specifications to the original state-space model have been proposed. \cite{knorr2000dynamic} considered time-dependent team abilities in soccer and basketball using a first-order random walk. \cite{baker2015time} assumed a dynamic, non mean-reverting model of team strength to answer the question of who was the `best team ever.' An exponentially-weighted moving average of team strength was suggested by \cite{cattelan2013dynamic}, who found roughly similar performances when comparing weighted and unweighted versions. Most recently, \cite{manner2015modeling} combined predictions from a state-space model (with an AR(1) assumption) to those from betting markets. These authors also found differences in the variability of team strength parameters, although those levels of variability appeared to operate independent of team strength (e.g. low variances were possible for both good and bad teams). Interestingly, errors were random and normally distributed (e.g., no streakiness). \mike{Cut this down?}

%As additional and related BTM resources, team-specific home advantages (HFA) using a BTM were compared to a constant HFA model by \cite{tutz2015extended} in soccer and \cite{koopmeiners2012comparison} in football. \cite{matthews2005improving} considered data transformations of NFL score outcomes to account for blowouts in BTM's, and \cite{owen2011dynamic} used dynamic Bayesian models in association football with evolution variance parameters. \cite{koopmeiners2012comparison} explicitly modeled the variance parameters of team strength in football, finding little change over time. 





\subsection{Betting market probabilities}

In many instances, researchers derive estimates of team strength in order to predict game-level probabilities. Betting market information has long been recommended to judge the accuracy of these probabilities \citep{harville1980predictions, stern1991probability}. Before each contest, sports books---including those in Las Vegas and in overseas markets---provide a price for each team, more commonly known as the money line. 

Mathematically, if team $i$'s line money line is $\ell_i$, then the boundary win probability for that team, $p_i(\ell_i)$, is given by:
$$
  p_i(\ell_i) = \begin{cases}
        \frac{100}{100 + \ell_i} & \text{ if } \ell_i > 0 \\
        \frac{|\ell_i|}{100 + |\ell_i|} & \text{ if } \ell_i < 0
      \end{cases} \,.
$$

The boundary win probability represents the threshold at which point betting on team $i$ would be profitable in the long run.

As an example, suppose the Chicago Cubs were favored ($\ell_i = -127$ on the money line) to beat the Arizona Diamondbacks ($\ell_j = 117$). The boundary win probabilities for the Cubs would be $p_i(-127) = 0.559$; for the Diamondbacks, $p_j(117) = 0.461$. The boundary win probabilities implied by the betting markets sum to greater than one by an amount collected by the sportsbook as profit (known colloquially as the ``vig" or ``vigorish").  However, it is straightforward to normalize these prices to sum to unity to estimate $p_{ij}$, the implied probability of $i$ defeating $j$: 
\begin{eqnarray}
  p_{ij} = \frac{p_i(\ell_i)}{p_i(\ell_i) + p_j(\ell_j)}. \label{eqn:moneyline}
\end{eqnarray}

\noindent In our example, dividing each boundary probability by $1.02 = (0.559 + 0.461)$ implies win probabilities of 54.8\% for the Cubs and 45.2\% for the Diamondbacks. 

In principle, money line prices account for all determinants of game outcomes known to the public prior to the game, including team strength, location, and injuries. Across time and sporting leagues, researchers have identified that these prices\ben{estimates? Are you trying to beat the price or the win probability implied by the price?} \mike{Think you are trying to beat both. To make money, you have to beat the price, which entails beating the win probability as well. I think?} are difficult to beat; i.e, that the betting markets are efficient. As an incomplete list, see \cite{harville1980predictions,  gandar1988testing, lacey1990estimation, stern1991probability, carlin1996improved, colquitt2001testing, spann2009sports, nichols2012impact, paul2014market, lopez2015building}. Interestingly, \cite{colquitt2001testing} suggested that the efficiency of college basketball markets was proportional to the amount of pre-game information available---this would suggest that markets in professional sports are as efficient as they come. \cite{manner2015modeling} merged predictions from a state-space model with those from betting markets, finding that the combination of both predictions only occasionally outperformed betting markets alone.

We are not aware of any published findings that have compared leagues using implied probabilities. Given the varying within-sport metrics of judging team quality and the flawed between-sport approaches that rely on wins and losses alone, we aim to extend paired comparison models using money line information to better capture relative team equivalence in a method that can be applied generally.

%In addition to being used as standards by which to judge predictive accuracy, betting markets have been used to suggest that NBA teams `tank' \citep{soebbing2013gamblers}, that bettors place larger shares of bets on the home team \citep{paul2011nfl}, and that markets do not move lines to attract an even number of bets on each side \citep{paul2008price, humphreys2014understanding}. We are not aware of any published findings that have compared leagues using implied probabilities. In one somewhat related cross-sport project, \cite{wolfson2015s} used BTM's and margin-of-victory BTM's to find a clear separation between two pairs of leagues, the NFL and the NBA versus the NHL and MLB, as far as predictive accuracy when testing out of sample.
testing out of sample.

\section{Validation of betting market data}

We begin by confirming the accuracy of betting market data with respect to game outcomes. Regular season game result and betting line data in the four major North American professional sports leagues (MLB, NBA, NFL, and NHL) were obtained for a nominal fee from Sports Insights (\url{https://www.sportsinsights.com}). Although these game results are not official, they are accurate and widely-used. The 2006--2016 seasons were included in our models, except for the NFL, which used only the 2006--2015 seasons.

<<include=FALSE>>=
load("data/bigfour.rda"); library(dplyr)
bigfour <- bigfour %>% mutate(sport = toupper(sport)) %>% 
  arrange(sport, Date)
head(bigfour)
mosaic::favstats(~vig, data = bigfour)
@

These data were more than 99.3\% complete in each league, in the sense that there existed a valid betting line for nearly all games in these four sports across this time period. Betting lines provided by Sports Insights are expressed as payouts, which we subsequently convert into implied probabilities. The average vig in our data set is \Sexpr{round(100 * mean(bigfour$vig), 2)}\%, but is always positive, resulting in revenue for the sportsbook over a long run of games. In circumstances where more than one betting line was available for a particular game, we included only the line from before the game started (this is known as the closing line). A summary of our data is shown in Table~\ref{tab:bigfour}. 


<<message=FALSE, results='asis'>>=
load("data/bigfour.rda")
bigfour <- bigfour %>% mutate(sport = toupper(sport))
library(dplyr)
library(xtable)

## Point differential metrics used above
pdiff <- bigfour %>% mutate(pdiff = visitor_score - home_score) %>% group_by(sport) %>%
  summarise(ave.diff = mean(abs(pdiff), na.rm = TRUE))

n.games <- data_frame(sport = c("MLB","NBA", "NFL", "NHL"), N_results = as.integer(c(26728, 13290, 2560, 13020)))
#Use updated n.games with newer bigfour.
bigfour %>%
  group_by(sport) %>%
  summarise(
    # games = n(), 
#            earliest = as.character(min(gameDate)), 
#            latest = as.character(max(gameDate)),
            num_teams = length(unique(setdiff(union(visitor_team, home_team), NA))), 
            mean_home_wp_actual = sum(home_win, na.rm = TRUE) / sum(!is.na(home_win)),
            n_bets = sum(!is.na(prob_home)), 
            mean_home_prob = mean(prob_home, na.rm = TRUE)) %>%
  left_join(n.games) %>%
  mutate(Coverage = n_bets / N_results) %>%
  select(sport, num_teams, N_results, mean_home_wp_actual, n_bets, mean_home_prob, Coverage) %>%
  rename(`Sport ($q$)` = sport, `$t_q$` = num_teams, 
         `$n_{games}$` = N_results, `$\\bar{p}_{games}$` = mean_home_wp_actual,
         `$n_{bets}$` = n_bets, `$\\bar{p}_{bets}$` = mean_home_prob) %>%
  xtable(caption = "Summary of cross-sport data. $t_q$ is the number of unique teams in each sport $q$. $n_{games}$ records the number of actual games played, while $n_{bets}$ records the number of those games for which we have a betting line. $\\bar{p}_{games}$ is the mean observed probability of a win for the home team, while $\\bar{p}_{bets}$ is the mean implied probability of a home win based on the betting line. Note that we have near total coverage (betting odds for almost every game) across all four major sports.", 
         digits = 3, label = "tab:bigfour", align = "llr|rr|rr|r") %>%
  print(include.rownames = FALSE, sanitize.colnames.function = function(x) x)
@


We also compared the observed probabilities of a home win to the corresponding probabilities implied by our betting market data (Figure~\ref{fig:betting}). In each of the four sports, the efficient market hypothesis cannot be rejected for any range of implied home win probabilities, based on visual inspection of a LOESS regression model. Thus, we find no evidence to suggest that the probabilities implied by our betting market data are biased or inaccurate---a conclusion that is supported by the body of academic literature referenced above. Accordingly, we interpret these probabilities ``true." 

<<betting, fig.height=10, fig.cap="Accuracy of probabilities implied by betting markets. Each dot represents a bin of implied probabilities rounded to the nearst hundredth. The size of each dot (N) is proportional to the number of games that lie in that bin. We note that across all four major sports, the observed winning percentages accord with those implied by the betting markets. The dotted diagonal line indicates a completely fair market where probabilities from the betting markets correspond exactly to observed outcomes. In each sport, this diagonal line lies entirely within the standard error surrounding a LOESS regression line, suggesting that an efficient market hypothesis cannot be rejected.">>=
bigfour_summary <- bigfour %>%
  group_by(sport) %>%
  summarize(N = n(), num_seasons = n_distinct(season), 
            earliest = min(gameDate), latest = max(gameDate),
            home_win_pct = sum(home_win, na.rm = TRUE) / n(), 
            prob_missing = sum(is.na(p_home)), 
            prob_pct = sum(!is.na(p_home)) / n(), 
            home_win_prob = mean(p_home, na.rm = TRUE))
bigfour_binned <- bigfour %>%
  mutate(p_home_bin = round(p_home, 2)) %>%
  group_by(sport, p_home_bin) %>%
  summarize(N = n(), home_win_bin_pct = mean(home_win))
library(ggplot2)
markets_plot <- ggplot(data = bigfour, 
                       aes(x = p_home, y = as.numeric(home_win), 
                           color = sport)) + 
  geom_point(alpha = 0.1) + 
  geom_point(data = bigfour_binned, 
             aes(x = p_home_bin, y = home_win_bin_pct, size = N), alpha = 0.5) + 
  geom_smooth() +
  geom_abline(slope = 1, intercept = 0, color = "black", lty = 2) + 
  geom_hline(data = bigfour_summary, 
             aes(yintercept = home_win_pct, color = sport), lty = 3) + 
  geom_vline(data = bigfour_summary, 
             aes(xintercept = home_win_prob, color = sport), lty = 3) + 
  coord_equal() + 
  scale_x_continuous("Betting Market Estimated Probability of Home Win", 
                     labels = scales::percent, limits = c(0,1)) + 
  scale_y_continuous("Observed Probability of Home Win", 
                     labels = scales::percent, limits = c(0,1)) + 
  facet_wrap(~sport)
#  facet_grid(sport ~ season)
markets_plot + theme_grey(base_size = 16) 
# ggsave(filename = "figure/betting_markets.pdf", plot = markets_plot, width = 10, height = 10)
@


\section{Bayesian state-space model}


Our model below builds on the state-space specification provided by \cite{glickman1998state} to provide a unified framework for contrasting the four major North American sports leagues.

Let $p_{(q,s,k)ij}$ be the probability that team $i$ will beat team $j$ in season $s$ during week $k$ of sports league $q$, where $q \in \{MLB, NBA, NFL, NHL\}$. These probabilities are assumed to be known, calculated using sportsbook odds via Equation (\ref{eqn:moneyline}). Letting $\theta_{(q,s,k) i}$ and $\theta_{(q, s, k) j}$ be season-week team strength parameters for teams $i$ and $j$, respectively, we assume that 

$$
E[logit(p_{(q,s,k) ij})] = \theta_{(q,s,k) i} - \theta_{(q, s, k) j} + \alpha_{(q) i},
$$
\mike{Above should be conditional? Also, I added the corresponding fit from the constant HA model. This comes next}

where $logit()$ is equivalent to the log-odds transform and $\alpha_{(q) i}$ is the home advantage (HA) parameter for a game played at the home of franchise $i$. In using the log-odds of victory, we have a cross-sport outcome that provides more information than only knowing which team won the game or what the score was.

Let ${\bf p}_{(q,s,k)}$ represent the vector of length $g_{(q,s,k)}$ (the number of games in week $k$ of season $s$ in league $q$) containing all of league $q$'s probabilities in week $k$ of season $s$. We then assume that
\begin{eqnarray}
\text{logit}({\bf p}_{(q,s,k)}) \sim N(\mathbf{\theta_{(q,s,k)}}\mathbf{X}_{q,s,k} + \alpha_{q_0}\mathbf{J}_{g_{q,s,k}} + \balpha_{q}\mathbf{Z}_{q,s,k}, \tau^{2}_{q,game}\mathbf{I}_{g_{(q,s,k)}}) ,   \label{model.full}
\end{eqnarray}

where $\mathbf{\theta_{(q,s,k)}}$ is a vector of length $t_{q}$ (the number of teams in league $q$) containing the team strength parameters in season $s$ during week $k$, $\alpha_{q_0}$ is the overall home field advantage parameter for sports league $q$, and $\balpha_{q}$ is a vector of length $t^{\star}_{q}$ containing \textit{franchise}-specific home advantage parameters for league $q$ that do not vary over time (i.e. HA is assumed to be constant for a team over weeks and seasons). Note that $t^{\star}_{q}$, the number of home venues in league $q$, is greater than or equal to $t_{q}$, the number of teams in league $q$, due to franchise relocation.\footnote{There were two franchise relocations in our data, Seattle to Oklahoma City (NBA) and Atlanta to Winnipeg (NHL).} $\mathbf{X}_{q,s,k}$ and $\mathbf{Z}_{q,s,k}$ contain $g_{(q,s,k)}$---the number of games in league $q$ during week $k$ of season $s$---rows and $t_{q}$ and $t^{\star}_{q}$ columns, respectively.   The matrix $\mathbf{X}_{q,s,k}$ contains the values $\{1, 0, -1\}$ where for a given row (i.e. one game) the value of $i^{th}$ column in that row is a 1/-1 if the $i^{th}$ team played at home/away in the given game and 0 otherwise.  $\mathbf{Z}_{q,s,k}$ is a matrix containing a 1 in the $i^{th}$ column if the $i^{th}$ team played the game corresponding to that row at home and 0 otherwise. Finally, $\tau^{2}_{q,game} = 1 / \sigma^{2}_{q,game}$ is the precision \mike{variance?}, $\mathbf{J}_{g_{q,s,k}}$ is a column vector of length $g_{q,s,k}$ containing all 1's, and $\mathbf{I}_{g_{(q,s,k)}}$ is an identity matrix with dimension ${g_{(q,s,k)}} \times {g_{(q,s,k)}}$.

In addition, we propose a simplified version of Model (\ref{model.full}), one that assumes that the HA within each sport is identical for each franchise, such that
\begin{eqnarray}
E[logit(p_{(q,s,k) ij})] &=& \theta_{(q,s,k) i} - \theta_{(q, s, k) j} + \alpha_{q_0}, \nonumber\\
\text{logit}({\bf p}_{(q,s,k)}) &\sim& N(\mathbf{\theta_{(q,s,k)}}\mathbf{X}_{q,s,k} + \alpha_{q_0}\mathbf{J}_{g_{q,s,k}}, \tau^{2}_{q,game}\mathbf{I}_{g_{(q,s,k)}}). \label{model.red} 
\end{eqnarray}

\noindent For Model (\ref{model.red}), matrices ${\bf p}_{(q,s,k)}$, $\mathbf{X}_{q,s,k}$, $\mathbf{J}_{g_{q,s,k}}$, and $\mathbf{I}_{g_{(q,s,k)}}$ are specified identically to Model (\ref{model.full}).

Similar to \cite{glickman1998state}, we allow the strength parameters of the teams to vary auto-regressively from week-to-week and from season-to-season. In general, this entails that team strength parameters are shrunk towards the league average over time in expectation. Formally,

$$
\theta_{(q,s+1,1)} | \gamma_{q,season}, \mathbf{\theta_{q,s,g_{q,s,.}}}, \tau^{2}_{q,season},  \sim N (\gamma_{q,season}\mathbf{\theta}_{(q,s,g_{q,s,.})},(\tau^{2}_{q,season})I_{t_{q}})
$$

\mike{Question about notation of $\mathbf{\theta_{q,s,g_{q,s,.}}}$. Why isn't this just $\mathbf{\theta_{q,s,k^{\star}_{q}}}$}

and 
$$
\theta_{(q,s,k+1)} | \gamma_{q,week}, \mathbf{\theta_{q,s,k}}, \tau^{2}_{q,week},  \sim N (\gamma_{q,week}\mathbf{\theta}_{(q,s,k)},(\tau^{2}_{q,week})I_{t_{q}})
$$

where $g_{q,s,.} = \sum_{k=1}^{k^{\star}_{q}} g_{q,s,k}$, $k^{\star}_{q}$ is the number of weeks in a season in league $q$, $\gamma_{q,week}$ is the autoregressive parameter from week-to-week and $\gamma_{q,season}$ is the autoregressive parameter from season-to-season.  

We depart from \cite{glickman1998state} here in our specification of precision.  Here, we estimate three parameters, $\tau^{2}_{q,game}$, $\tau^{2}_{q,season}$, and $\tau^{2}_{q,week}$, allowing for their separate estimation.

\mike{Do we need to identify that we depart from Glickman here? I'd just assume state that we estimate them separately. As it is now, seems like we need to better justify our departure choice, as the justification included isn't great.}

Given the time-varying nature of our specification, we use a Bayesian approach to obtain model estimates. For sport $q$, the team strength parameters for week $k=1$ and season $s=1$ have a prior distribution of
$$
\theta_{(q,1,1)i} \sim N(0, \tau^{2}_{q,season}) \,, \qquad \text{for } i \in 1, \ldots, t_{q}.
$$

Team specific home advantage parameters have a similar prior, namely, 
$$
\alpha_{(q)i}\sim N(0, \tau^{2}_{q,\alpha}) \,, \qquad \text{for } i \in 1, \ldots, t^{\star}_{q}.
$$

Finally, we assume the following prior distributions: 
\begin{align*}
\tau^{2}_{q,game} &\sim \Gamma(0.0001,0.0001) &\qquad
  \alpha_{q} &\sim N(0,10000) \\
\tau^{2}_{q,season} &\sim \Gamma(0.0001,0.0001) &\qquad
  \gamma_{q,season} &\sim Uniform(0,2) \\
\tau^{2}_{q,week} &\sim \Gamma(0.0001,0.0001) &\qquad
  \gamma_{q,week} &\sim Uniform(0,2) \\
\tau^{2}_{q,\alpha} &\sim \Gamma(0.0001,0.0001) && \\
\end{align*}

Our primary interest lies in three levels of variability with respect to the $\theta_{(q,s,k)}$'s. First, there is variability at any fixed time $s$ and $k$ across $i$. This reflects the between-team variability in team strength; in other words, how equivalent are the teams to one another at a given snapshot in time? Second, there is variability across $k$, reflected in the week-to-week autoregressive parameter, $\gamma_{q,week}$. This generalizes to how teams can improve or worsen over the course of a season. Third, there is variability across $s$, corresponding to the season-to-season autoregressive parameter, $\gamma_{q,season}$. This accounts for larger changes to team ability that can occur between seasons. 

Posterior distributions of each parameter are estimated using Markov Chain Monte Carlo (MCMC) methods. We used Gibbs sampling via the \pkg{rjags} package \citep{rjags} in the \R statistical computing environment to obtain posterior distributions, done separately for each $q$. Three chains---using 40,000 iterations after a burn-in of 2,000 draws, fit with a thin of 5 to reduce the autocorrelation within chains---yielded 8,000 posterior samples in each $q$. Visual inspection of trace plots with parallel chains are used to confirm convergence. Comparisons of Models (\ref{model.full}) and (\ref{model.red}) are made using the Deviance Information Criterion (DIC, \cite{spiegelhalter2002bayesian}).

While we are unable to share our betting market data due to licensing restrictions, the data wrangling code, Gibbs sampling code, posterior draws, and the code used to obtain posterior estimates and figures are all posted to a GitHub repository, available at \url{https://github.com/bigfour/competitiveness}.


\section{Results}

\subsection{Model fit}

Trace plots of  $\alpha_{q_0}$, $\gamma_{q, season}$, $\gamma_{q, week}$ $\tau_{q, game}$, $\tau_{q, season}$, and $\tau_{q, week}$ are shown for each $q$ in Figures \ref{fig:MLBtrace}, \ref{fig:NBAtrace}, \ref{fig:NFLtrace}, and \ref{fig:NHLtrace} in the Appendix. Visual inspection of these plots does not provide evidence of a lack of convergence or of an autocorrelation between draws. These trace plots stem from Model~(\ref{model.full}); conclusions are similar when plotting draws from Model~(\ref{model.red}). 

Table~\ref{tab:DIC} shows the DIC for each fit in each league, along with the difference in DIC values and its standard error. In each of the leagues, fits with a team-specific HA (Model (\ref{model.full})) yielded significantly lower DIC's (lower is better), with the most noticeable difference in fit improvement in the NBA.

\begin{table}[!ht]
\makebox[\linewidth]{
\begin{tabular}{l r r r}
\hline
 & Model (\ref{model.full}), unique HA & Model (\ref{model.red}), constant HA & Difference (SE) \\ \hline
MLB &  -8548 & -8522  & -25.7 (10.8) \\
NBA & 6886 & 7224 & -337.4 (26.6) \\
NFL & -1230  & -1216 & -13.6 (3.3) \\
NHL & -18335  & -18148 & -187.6 (20.7)\\
\hline
\end{tabular}
}
\caption{Deviance information criterion (DIC) by sport and model, along with the difference in DIC (standard errors (SE) of the difference shown in parenthesis, HA: home advantage) \label{tab:DIC}}
\end{table}

Taken wholly, this suggests that perceived differences in the home advantage between teams in each league are likely not accounted for due to chance alone, with NBA teams showing the largest team-to-team differences in the HA. As such, results that follow use model estimates from Model (\ref{model.full}). 

\subsection{Team strength}



Table \ref{tab:betas} shows summary statistics of the team strength estimates from posterior draws. Overall, there tends to be larger variability in team strength parameters at any given point in time in both the NFL and NBA, with posterior team strength coefficients tending to vary between -1 and 1 (on the logit scale). For reference, a team-strength of 1.0 on the log-odds scale implies an $\frac{e^{1.0}}{1+e^{1.0}} = 73.1$\% chance of beating a league average team in a game played at a neutral site. The standard deviation of team strength is smallest in MLB, suggesting that, relative to the other leagues, team talent is more tighly packed. Relative to MLB, spread of team strengths are about 1.3, 3.0, and 3.6 times wider in the NHL, NFL, and NBA, respectively.


<<echo=FALSE, results='asis'>>=
load(file.path(root, "data", "tidy_betas.rda"))
library(xtable)
tidy_betas %>%
  mutate(sport = toupper(sport)) %>%
  group_by(sport) %>%
  summarize(N = n(), 
            min = min(beta),
            CIL = quantile(beta, probs = 0.05),
            Q1 = quantile(beta, probs = 0.25),
            mean = mean(beta), 
            Q3 = quantile(beta, probs = 0.75),
            CIR = quantile(beta, probs = 0.95),
            max = max(beta),
            sd = sd(beta)) %>%
  rename(`N*` = N, `$5^{th}$` = CIL, `$95^{th}$` = CIR) %>%
  xtable(caption = "Summary of team strength parameters, taken on the log-odds scale. N*: number of unique team strength draws (teams $\\times$ seasons $\\times$ weeks)", 
         digits = 3, label = "tab:betas") %>%
  print(include.rownames = FALSE, sanitize.text.function = identity)
@


Figure~\ref{fig:spaghetti} shows estimated team strength coefficients over time, approximated using posterior mean draws for all weeks $k$ and seasons $s$ across all four sports leagues. Figures~\ref{fig:spaghetti-mlb}, \ref{fig:spaghetti-nba}, \ref{fig:spaghetti-nfl}, and \ref{fig:spaghetti-nhl} (shown in the Appendix) provide an individual plot for each sport, which include divisional facets to allow easier identification of individual teams. Teams in Figures~\ref{fig:spaghetti} and \ref{fig:spaghetti-mlb}--\ref{fig:spaghetti-nhl} are depicted using their two primary colors, scraped from \url{http://jim-nielsen.com/teamcolors/} via the \pkg{teamcolors} package (\url{https://github.com/beanumber/teamcolors}) in \R. 

<<set-colors, echo=FALSE>>=
library(dplyr)
# load(file.path(root, "data", "tidy_betas.rda"))
tidy_betas <- tidy_betas %>%
  mutate(sport = toupper(sport),
         annotation = "",
         annotation = ifelse(beta == max(beta), 
                             paste0("Strongest team (", name, ")"), 
                             annotation),
         annotation = ifelse(beta == min(beta), 
                             paste0("Weakest team (", name, ")"), 
                             annotation))
colors <- tidy_betas %>%
  select(name, primary, secondary) %>%
  unique()
primary <- colors$primary
secondary <- colors$secondary
names(primary) <- colors$name
names(secondary) <- colors$name
@

<<set-divisions>>=
library(teamcolors)

###### Football only
div <- c("AFC East", "AFC West", "AFC North", "AFC South", 
         "NFC East", "NFC West", "NFC North", "NFC South")
div.teams.NFL <- c(div[6], div[8], div[3], div[1], div[8], 
               div[3], div[3], div[5], div[7], div[2],
               div[7], div[7], div[4], div[4], div[4],
               div[2], div[6], div[1], div[7], div[1], div[8],
               div[5], div[1], div[2], div[5], div[3], 
               div[2], div[6], div[6],  div[8], 
               div[4], div[5])
divisions_nfl <- data_frame(sport = "nfl", division = div.teams.NFL)
divisions_nfl$team <- teamcolors %>%
  filter(sport == "nfl") %>%
  select(name) %>%
  unlist()
# divisions %>% arrange(division)

###### MLB only
div <- c("AL East", "AL Central", "AL West",
         "NL East", "NL Central", "NL West")
div.teams.MLB <- c(div[6], div[4], div[1], 
               div[1], div[5], div[2],
               div[5], div[6], div[2], 
               div[2], div[3], div[2], 
               div[3], div[6], div[4],
               div[5], div[2], div[4], 
               div[1], div[3], div[4],
               div[5], div[6], div[6], 
               div[3], div[5], div[1], 
               div[3], div[1], div[4])
divisions_mlb <- data_frame(sport = "mlb", division = div.teams.MLB)
divisions_mlb$team <- teamcolors %>%
  filter(sport == "mlb") %>%
  select(name) %>%
  unlist()
# divisions_mlb %>% arrange(division) %>% print(n = Inf)


###### NBA only
div <- c("Atlantic", "Central", "Southeast",
         "Pacific", "Southwest", "Northwest")
div.teams.NBA <- c(div[3], div[1], div[1], 
               div[3], div[2], div[2],
               div[5], div[6], div[2], 
               div[4], div[5], div[2], 
               div[4], div[4], div[5],
               div[3], div[2], div[6], 
               div[5], div[1], div[6],
               div[3], div[1], div[4], 
               div[6], div[4], div[5], 
               div[1], div[6], div[3])
divisions_nba <- data_frame(sport = "nba", division = div.teams.NBA)
divisions_nba$team <- teamcolors %>%
  filter(sport == "nba") %>%
  select(name) %>%
  unlist()
# divisions_nba %>% arrange(division) %>% print(n = Inf)



###### Hockey only
div <- c("Metro", "Atlantic", "Central", "Pacific")
div.teams.NHL <- c(div[4], div[4], div[2], div[2], div[4], 
               div[1], div[3], div[3], div[1], div[3],
               div[2], div[4], div[2], div[4], div[3], 
               div[2], div[3], div[1], div[1], div[1],
               div[2], div[1], div[1], div[4], div[3], 
               div[2], div[2], div[4], div[1], div[3])
divisions_nhl <- data_frame(sport = "nhl", division = div.teams.NHL)
divisions_nhl$team <- teamcolors %>%
  filter(sport == "nhl") %>%
  select(name) %>%
  unlist()
# divisions_nhl %>% arrange(division) %>% print(n = Inf)

divisions <- rbind(divisions_nfl, divisions_mlb, divisions_nba, divisions_nhl)
teamcolors <- teamcolors %>%
  left_join(divisions, by = c("sport" = "sport", "name" = "team")) %>%
  mutate(name = ifelse(name == "Los Angeles Angels of Anaheim", "Los Angeles Angels", name),
         name = ifelse(name == "St Louis Blues", "St. Louis Blues", name)) 
@

<<>>=
tidy_betas <- tidy_betas %>%
  left_join(select(teamcolors, name, division), by = c("name" = "name")) %>%
  mutate(time_val = ifelse(sport == "NFL" | sport == "MLB", 
                           time_val + 1, time_val))
max.beta <- round(max(tidy_betas$beta), 2)
min.beta <- round(min(tidy_betas$beta), 2)
@


<<spaghetti-base>>=
library(ggplot2)
spag <- ggplot(data = tidy_betas, 
       aes(x = time_val, y = beta, 
           color = name, fill = name)) +
  geom_line(alpha = 0.5) + 
  geom_point(shape = 21, size = 0.5, alpha = 0.8) + 
  geom_text(aes(label = annotation), color = "black", hjust = "left", nudge_x = 0.25) + 
  scale_color_manual(name = NULL, values = primary) + 
  scale_fill_manual(name = NULL, values = secondary) + 
  scale_x_continuous(name = "Season", breaks = 2005:2016) +
  scale_y_continuous(name = "Team Strength (log odds scale)") + 
  guides(color = FALSE, fill = FALSE) +
  #  guides(color = guide_legend(ncol = 2)) 
  theme_grey(base_size = 18)
@

<<spaghetti, fig.height=13.5, fig.cap="Team strengths over time for all four sports. MLB and NFL seasons follow each yearly tick mark on the x-axis, while NBA and NHL seasons occur during years labeled by adjacent tick marks.">>=
spag + facet_wrap(~sport, ncol = 1)
@

<<spag_sport>>=
spag_sport <- function(sport_name) {
  x <- filter(tidy_betas, sport == sport_name)
  spag %+% x + 
    geom_line(data = select(x, -division), color = "darkgray", alpha = 0.3) + 
    geom_line(alpha = 0.5) + 
    geom_point(shape = 21, size = 0.5, alpha = 0.8) + 
    facet_wrap(~division, ncol = 2) + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
    ggtitle(paste("Team strengths over time,", sport_name))
}
@

<<include=FALSE, eval=FALSE>>=
# deprecated
graph.sport <- function(sport){

year.max <- 2016
if (sport == "NFL"){year.max = 2015}

sport1 <- eval(sport)
sportcolors <- subset(tidy_betas, sport == sport1)
sportcolors <- sportcolors %>%
  select(name, primary, secondary) %>%
  unique()

if (sport == "NFL"){sportcolors$division <- div.teams.NFL}
if (sport == "NHL"){sportcolors$division <- div.teams.NHL}
if (sport == "NBA"){sportcolors$division <- div.teams.NBA}
if (sport == "MLB"){sportcolors$division <- div.teams.MLB}
datbetas3 <- inner_join(tidy_betas, sportcolors, by = c("name" = "name"))
datbetas.null <- select(datbetas3, -division)
datbetas.null <- arrange(datbetas.null, time_val)


##### Generate plots
lim <- max(abs(datbetas.null$beta))
gg <- ggplot()  + ggtitle(paste("Team strengths over time,", sport)) + xlab("Year")  + 
                            ylab("Log-odds of a win")
gg <- gg + geom_path(data = datbetas.null, colour = "grey", 
                     aes(x = time_val, y = beta, group = name)) +
  scale_y_continuous(lim = c(-lim, lim)) +
  scale_x_continuous(breaks = c(2005:2016), labels = c(2005:2016)) 


for (i in 1:nrow(sportcolors)){
    gg <- gg + geom_line(data = filter(datbetas3,name==sportcolors$name[i]),aes(x = time_val, y = beta),linetype=1,lwd=1.5,colour=sportcolors$primary[i]) 
    gg <- gg + geom_line(data = filter(datbetas3,name==sportcolors$name[i]),aes(x = time_val, y = beta),linetype=2,lwd=1.5,colour=sportcolors$secondary[i]) 
  }
gg1 <- gg +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
gg2 <- gg1 + facet_wrap(~division, nrow = 2)
return(gg2)
}

#NFL: 2006:2015
#NBA, NHL: 2005:2016

nhl.team <- graph.sport("NHL")
nba.team <- graph.sport("NBA")
nfl.team <- graph.sport("NFL")
mlb.team <- graph.sport("MLB")
### These charts will be called in the appendix
@

Figure~\ref{fig:spaghetti} and Table~\ref{tab:betas} both identify wide-gaps in average team talent when comparing each of the NBA and the NFL to the NHL and MLB. These findings stand somewhat in contrast to competitive balance as measured using Noll-Scully, which argues that both the NHL and the NFL are less competitively balanced than MLB \citep{WagesWins}. One likely explanation is that because Noll-Scully increases with a larger number of games played (higher = less balanced), MLB (162 games) appears less balanced under Noll-Scully than it actually is and the NFL (16 games) appears more balanced. Like Noll-Scully, we conclude that the NBA does not show competitive balance relative to other leagues. 

Our figures also identify several other interesting observations. For example, the New England Patriots of the NFL stand out with the top performance in the last decade, with an average team strength of \Sexpr{max.beta} on the log-odds scale, observed during Week 11 of 2007. In that season, New England finished the regular season 16-0 before eventually losing in the Super Bowl. The worst performance belongs to the NBA's Miami Heat, which during week 23 of the 2007--08 season averaged a posterior team strength of \Sexpr{min.beta}. That Heat team finished with an overall record of 15-67, at one point losing 15 consecutive contests. Related, it is interesting that the team strength estimates of bad teams in the NBA (e.g. the Heat in 2007--08) lie further from 0 than the estimates for good teams. This possibly reveals the tendency for teams in this league to ``tank"---a strategy of fielding a weak team intentionally to improve the chances of having better selection preference in the upcoming player draft \citep{soebbing2013gamblers}.

Another observation is that in the NHL, top teams appear less dominant than a decade ago. For example, there are seven NHL team-seasons where an average posterior strength estimate of 0.55 or greater was reached; each of these came during or prior to the 2008--09 season.  In addition to an increased amount of parity, the league's point system change in 2005--06, which unintentionally encouraged teams to play more overtime games \citep{lopez2013inefficiencies}, could be responsible. More overtime contests could lead to different perceptions in how betting markets view team strengths, as overtime sessions and the resulting shootouts are, by and large, coin flips \citep{lopez2016predicting}. 

As a final point of clarification in Figures \ref{fig:spaghetti}, \ref{fig:spaghetti-nba}, and \ref{fig:spaghetti-nhl}, the periods with straight lines of team strength estimates in the 2012-13 season (NHL) and 2011-12 season (NBA) reflect games lost due to lockouts. 

<<include=FALSE>>=
tidy_betas %>%
  filter(sport == "NHL", beta > 0.55) %>% 
  select(beta, time_val, season, name) %>% 
  mutate(team.seas = paste(season, name)) %>% 
  arrange(team.seas) %>% 
  print.data.frame() 
@

\subsection{Variance and autoregressive parameters}


Table \ref{tab:params} shows the median posterior draw, along with 95\% credible intervals, for $\gamma_{q, season}$, $\gamma_{q, week}$ $\tau_{q, game}$, $\tau_{q, season}$, and $\tau_{q, week}$ for each $q$. 
\mike{I want to use three digits here but the table is too wide. Thoughts?}
<<echo=FALSE, results='asis'>>=
load("data/params.rda")
library(xtable)
params %>%
  select(-alpha) %>%
  mutate(sport = toupper(sport), sigma_w = sqrt(sigma_w), sigma_g = sqrt(sigma_g), sigma_s = sqrt(sigma_s)) %>%
  tidyr::gather(key = "param", value = "val", -sport) %>%
  group_by(sport, param) %>%
  summarize(med.sport = median(val), lb = quantile(val, 0.025), ub = quantile(val, 0.975)) %>%
  mutate(CI = paste(round(med.sport, 2), " (", round(lb, 2), ", ", round(ub, 2),")", sep = "")) %>% 
  select(sport, param, CI) %>%
  tidyr::spread(param, CI) %>%
  rename(`$\\gamma_{q, week}$` = gamma_w, 
         `$\\gamma_{q, season}$` = gamma_s, 
         `$\\tau_{q, week}$` = sigma_w, 
         `$\\tau_{q, season}$` = sigma_s, 
         `$\\tau_{q, game}$` = sigma_g, 
         `Sport ($q$)` = sport) %>%
  xtable(caption = "Median posterior draw (and 95 percent credible intervals) by league.", 
         digits = 3, label = "tab:params") %>%
  print(include.rownames = FALSE, sanitize.text.function = identity)
@

Posterior draws of $\tau_{q, game}$ find the highest game-level errors in our log-odds probability estimates occur in the NBA (median posterior draw of $\tau_{NBA, game}$ = 0.273), followed in order by $\tau_{NFL, game}$, $\tau_{MLB, game}$, and $\tau_{NHL, game}$. Interestingly, although its posterior distribution of team strength estimates was relatively narrow, MLB's game-level error rate, $\tau_{MLB, game}$, is relatively similar to $\tau_{NFL, game}$, at around 0.20. We posit that this additional game-level error in MLB is a function of the league's pitching match-ups, in which teams rotate through a handful of starting pitchers of varying calibers.

We also examine the joint distribution of the variability in team strength on a season-to-season ($\tau_{q,season}$) and week-to-week ($\tau_{q,week}$) basis via contour plots in Figure~\ref{fig:contourSigma}, using separate colors for each $q$. 

The highest uncertainty with respect to team strength occurs with the NBA, followed in order by the NFL, NHL, and MLB. There are a couple of plausible explanations regarding the increased uncertainty in NBA team strength on a weekly basis. Injuries, the resting of starters, and in-season trades would seemingly have a larger impact in a sport like basketball where fewer players are participating at a single point in time. In particular, our model cannot precisely gauge team strength when star players, who could play, are rested in favor of lesser alternatives. Relative to the other professional leagues, star players take on a more important role in the NBA \citep{berri2006road}, a fact undoubtably picked up by betting markets. That said, while there is increased variability in our estimate of NBA team strengths, when considering differences in team talent to begin with, these absolute differences are not as extreme (e.g., a difference in team strength of 0.05 means less in the NBA than in the NHL). 


<<contourSigma, fig.cap="Contour plot of the estimated season-to-season and week-to-week variability across all four major sports leagues.">>=
load("data/params.rda")
nfl.sum <- params %>% 
  filter(sport == "nfl") %>% 
  summarise(mean.week = round(mean(gamma_w), 2), 
            mean.season = round(mean(gamma_s), 2), 
            low.bound = round(quantile(gamma_s, 0.025), 2), 
            upp.bound = round(quantile(gamma_s, 0.975), 2))

ggplot(params, aes(x = sqrt(sigma_w), y = sqrt(sigma_s), 
                   color = toupper(sport))) + 
  geom_density_2d() + geom_point(alpha = 0.1)  + 
  xlab(expression(tau[week])) + 
  ylab(expression(tau[season])) + 
  scale_colour_brewer(palette = "Set1", "League") + 
  theme_grey(base_size = 16) 
@

\mike{The JAGS output gives us precision, which we have been (correctly) inverting to get the variance. To this point, however, we had been plotting the variance but calling it the standard deviation. I think it makes more sense to plot the standard deviation? As a result, you'll notice this plot has slightly changed.}

<<contourGamma, fig.cap="Contour plot of the estimated season-to-season and week-to-week autoregressive parameters across all four major sports leagues.">>=
ggplot(params, aes(x = gamma_w, y = gamma_s, color = toupper(sport))) + 
  geom_vline(xintercept = 1, color = "darkgray", linetype = 2) + 
  annotate("text", x = 1.001, y = 0.85, 
           label = "Random\nWalk", hjust = "left") + 
  geom_density_2d() + geom_point(alpha = 0.1) + 
  xlab(expression(gamma[week])) + 
  ylab(expression(gamma[season]))+ 
  scale_colour_brewer(palette = "Set1", "League") + 
  theme_grey(base_size = 16) 
@

Likewise, figure~\ref{fig:contourGamma} displays the joint posterior distribution of $\gamma_{q, season}$ and $\gamma_{q, week}$ via contour plots for each $q$. On a season-to-season basis, team strengths in each of the leagues tend to revert towards the league average (0), as all draws of $\gamma_{q, season} < 1$ for all $q$. Reversion towards the mean is largest in the NHL (estimated $\gamma_{NHL, season}$ = 0.54, implying 46\% reversion), followed by the NBA (38\%), MLB (38\% reversion), and the NFL (31\%). However, there is enough uncertainty in the posterior distribution of these estimates that we are unable to say for certain if the differences in the season-to-season estimates between MLB, the NBA, and the NBA are significant. 

For each of the NHL, NBA, and NFL, posterior estimates of $\gamma_{q, week}$ (as well as 95\% credible intervals) imply an autoregressive nature to team caliber within each season. Interestingly, the NBA and NFL are the least consistent leagues on a week-to-week basis. In MLB, meanwhile, team strength estimates quite possibly follow a random walk (as in $\gamma_{MLB, week} = 1$), in which the succession of team strength estimates over time follows no identifiable pattern. 

Finally, it is worth pointing out that our estimates for $\gamma_{NFL,week}$ and $\gamma_{NFL,season}$, \Sexpr{nfl.sum$mean.week} and \Sexpr{nfl.sum$mean.season}, respectively, do not noticeably diverge from the estimates observed in \cite{glickman1998state} (0.99 and 0.82). Further, our estimates are more precise. For example, our 95\% credible interval for $\gamma_{NFL,season}$ is (\Sexpr{nfl.sum$low.bound}, \Sexpr{nfl.sum$upp.bound}); in \cite{glickman1998state}, it was (0.52, 1.28). To be fair, however, it is unclear is this increased precision is a function of our model specification (using log-odds of the probability of a win as the outcome, compared to point differential) or because we used a larger sample of seasons (10, compared to 5). 

As in \cite{glickman1998state}, we also observe an inverse link in posterior draws of $\gamma_{NFL,week}$ and $\gamma_{NFL,season}$. Given that total shrinkage across time is the composite of within and between-season shrinkage, such an association is not surprising \citep{glickman1998state}. If one source of reversion towards the average were to increase, the other would likely compensate by decreasing. 



\subsection{The home advantage}

Figure \ref{fig:alphaAll} shows the 2.5th, median, and 97.5th draws of each team's estimated home advantage parameter, presented on the log-odds scale. These are calculated by summing draws of $\alpha_{q_0}$ with $\alpha_{(q)i}$ for all $i$. HAs are shown in order to provide a sense of the magnitude of differences between the home advantage provided in the MLB (increased log-odds of a home win around 0.16, or about $e^{0.16} - 1 = 17$\% higher), NHL (0.22, or 25\%), NFL (0.36, or 43\%), and NBA (0.50, or 62\%).  The two franchises that have relocated in the last decade, the Atlanta Thrashers (NHL) and Seattle Supersonics (NBA), are also included for the games played in those respective cities. 

<<ha-plot>>=
## Home advantage plots
load("data/tidy_alphas.rda")
library(ggplot2)
datbetas.null <- tidy_alphas %>%
  mutate(sport = toupper(sport)) %>%
  group_by(sport) %>%
  arrange(alpha.team.overall) %>%
  mutate(rank.within = 1:n()) 
datbetas.empty <- datbetas.null %>% ungroup() %>% select(-sport)

gg <- ggplot(datbetas.null)  + ggtitle("Who has the best home advantage? Increased log-odds of winning at home, by team") 
gg1 <- gg + geom_point(data = datbetas.empty, colour = "grey", 
                       aes(y=alpha.team.overall, x=rank.within, group = team)) + 
  geom_errorbar(data = datbetas.empty, colour = "grey", 
                aes(x=rank.within, ymax = alpha.team.upper, 
                    ymin=alpha.team.lower, group = team), width=0.2) 

for (i in 1:nrow(datbetas.null)){
  df.temp <- slice(ungroup(datbetas.null), i)
  df.plot <- data.frame(x = rep(df.temp$rank.within, 2), y = c(df.temp$alpha.team.lower, df.temp$alpha.team.upper), 
                        z = df.temp$alpha.team.overall, sport = df.temp$sport, lab = df.temp$team)
  df.text <- data.frame(x = df.temp$rank.within, y = -0.21, team = df.temp$team, sport = df.temp$sport)
  gg1 <- gg1 + geom_line(data = df.plot,
                         aes(x = x, y = y), linetype=1, lwd=1.5, colour=df.temp$primary) 
  gg1 <- gg1 + geom_line(data = df.plot,
                         aes(x = x, y = y), linetype=2, lwd=1.5, colour=df.temp$secondary) 
  gg1 <- gg1 + geom_point(data = df.plot,
                          aes(x = x, y = z), colour=df.temp$secondary, size = 1.5) 
  gg1 <- gg1 + geom_text(data = df.text, aes(x = x, y = y, label = team, hjust = "left"), 
                         colour=df.temp$primary, size = 3)
}
@

<<ha-plot-full>>=
gg2 <- gg1  + coord_flip() + facet_wrap(~sport) + 
  xlab("") + ylab("") +
  theme_grey(base_size = 12)  +  
  theme(axis.line=element_blank(),
       axis.text.y=element_blank(), 
       axis.ticks.y=element_blank(),
       axis.title.y=element_blank()) + 
  scale_y_continuous(labels = c("0.00", "0.25", "0.50", "0.75"), breaks = c(0:3)/4) + 
  scale_x_continuous()
@

<<ha-plot-summary>>=
## Alternative plot
load("data/tidy_alphas.rda")
tidy_alphas <- tidy_alphas %>%
  mutate(sport = toupper(sport)) 

tidy_alphas$sport <- factor(tidy_alphas$sport,
    levels = c("MLB", "NHL", "NFL", "NBA"), ordered = TRUE)

library(stringr)
tidy_alphas.limits <- tidy_alphas %>%
  mutate(team.name = word(team, -1)) %>%
   group_by(sport) %>%
  arrange(alpha.team) %>%
   filter(alpha.team.overall > 0.6|team.name == "Rockies")

exp.fun <- function(x){log(x/(1-x))}
breaks <- c(exp.fun(0.5), exp.fun(0.55), exp.fun(0.6), exp.fun(0.65),
            exp.fun(0.7))
labels <- paste0(seq(50, 70, by = 5), "%")

gg3 <- ggplot(tidy_alphas, aes(sport, alpha.team.overall)) + 
  geom_dotplot(binaxis = "y", stackdir = "center", binwidth = 0.005) + 
  coord_flip() + geom_point(data = tidy_alphas.limits, 
                  aes(sport, alpha.team.overall), size = 0.5) +
  geom_text(data = tidy_alphas.limits, 
                  aes(sport, alpha.team.overall, label = team.name), 
            angle = 45, hjust = 1, vjust = 1, size = 3) +
  scale_y_continuous(lim = c(0, 0.7), breaks = breaks, 
                     labels = labels, "") + 
  xlab("") +
  labs(title = "Probability of beating an equal caliber opponent at home")
@

<<ha-plot-simple>>=
tidy_alpha_prob <- tidy_alphas %>%
  mutate(alpha_prob = mosaic::ilogit(alpha.team.overall), 
         top_half = alpha_prob < 0.58)
tidy_alpha_summary <- tidy_alpha_prob %>%
  group_by(sport) %>%
  summarize(N = n(), median_ha = median(alpha_prob))

gg4 <- ggplot(data = tidy_alpha_prob, 
              aes(y = alpha_prob, 
                  x = reorder(team, alpha_prob), 
                  color = sport)) + 
  geom_hline(data = tidy_alpha_summary, alpha = 0.5,
             aes(yintercept = median_ha, color = sport)) + 
  geom_errorbar(aes(ymin = mosaic::ilogit(alpha.team.lower), 
                    ymax = mosaic::ilogit(alpha.team.upper))) +
  geom_point() + 
  coord_flip() + 
  scale_x_discrete(NULL) + 
  scale_y_continuous("Probability of beating an equal caliber opponent at home", 
                     breaks = tidy_alpha_summary$median_ha, 
                     labels = round(tidy_alpha_summary$median_ha, 3),
                     minor_breaks = NULL) + 
  ggtitle("Estimated Home Advantage by Franchise")
@

<<alphaAll, fig.height = 10.8, fig.width = 8, fig.cap="Median posterior draw (with 2.5th, 97.5th quantiles) of each franchise's home advantage intercept, on the probability scale. We note that the magnitude of home advantages are strongly segregated by sport, with only one exception (the Colorado Rockies). We also note that no NFL team, nor any MLB team other than the Rockies, has a home advantage whose 95\\% credible interval does not contain the league median. ">>=
gg4 + theme(axis.text = element_text(size = 7))
# This will facet, but I think it is too confusing
# + facet_wrap(~top_half, scales = "free_y") + 
#  theme(strip.background = element_blank(),
#        strip.text.x = element_blank())
@


<<include=FALSE>>=
load("data/tidy_alphas.rda")
leagues <- tidy_alphas %>% group_by(sport) %>% summarise(mean.sport = mean(alpha.sport))
teams <- tidy_alphas %>% 
  filter(sport == "nba") %>% 
  group_by(team) %>% summarise(mean.post = mean(alpha.team.overall)) %>% 
  arrange(mean.post) %>% slice(c(1,n()))

league.ave <- round(exp(leagues$mean.sport[2])/(1+exp(leagues$mean.sport[2])), 3)
league.high <- round(exp(teams$mean.post[2])/(1+exp(teams$mean.post[2])), 3)
league.low <- round(exp(teams$mean.post[1])/(1+exp(teams$mean.post[1])), 3)
@


Figure \ref{fig:alphaAll} depicts substantial between-franchise differences within both the NBA and NHL. Conversely, HA estimates within the NFL and MLB are, by and large, more consistent across franchises. Interestingly, the home advantages of a few NFL franchises are skewed (see Denver and Seattle, relative to Detroit), potentially the result of a shorter regular season. Alternatively, HA may vary by season, game time, or the day of the game. Anecdotally, night games (Thursday, Sunday, or Monday) conceivably offer a larger HA than those played during the day \citep{Seahawks}. Informally, team-level HA estimates are similar in effect size to those depicted by \cite{koopmeiners2012comparison} in the NFL.

In the NBA, the league's best HA is found in Denver (increased log-odds of a win, \Sexpr{round(teams$mean.post[2], 3)}), with the worst shown in Brooklyn (\Sexpr{round(teams$mean.post[1], 3)}). The extreme home advantage provided to Denver (and to Utah, which ranks second) matches the results of \cite{Jazz}, who found significantly better performances when comparing Denver and Utah to the rest of the league with respect to home and road point differential. In MLB, the Colorado Rockies stand out for having the highest home advantage, as the remaining 29 teams boast overlapping credible intervals. We note that teams playing at home in Denver have the largest home advantages in MLB and the NBA, the 3rd-highest in the NFL, and the 8th-highest in the NHL. We speculate that this consistent advantage across sports is related to the home team's acclimation to the city's notably high altitude.  

Such distinctions have plausible impacts on league standings. An NBA team with a typical home advantage can expect to win \Sexpr{100*league.ave}\% of home games against a like-caliber opponent; for Brooklyn, the corresponding figure is \Sexpr{100*league.low}\%, while for Denver, \Sexpr{100*league.high}\%. Across 41 games (the number each team plays at home), this implies that Denver's home advantage is worth an extra \Sexpr{round(41*(league.high-league.ave), 2)} wins in a single season, relative to a league average team. Compared to Brooklyn, Denver's home advantage has been worth an estimated \Sexpr{round(41*(league.high-league.low), 2)} wins per year. 

As one important caveat, our models do not account for varying line-up and injury information. If opposing teams were to rest their star players at Denver, for example, our model would artificially inflate Denver's home advantage. 


\subsection{Validation of team strength estimates}

We begin the final steps of our analysis by comparing our team strength estimates to won-loss percentage and point differential. Ultimately, estimates from Model~(\ref{model.full}) are designed to estimate team quality at any given point in a season. If these estimates more properly assess team quality than won-loss percentage and point differential, they should more accurately assess future performance, such as how well teams will do over remaining games in a season.  

Figure~\ref{fig:R2} shows the coefficient of determination comparing each team's future won-loss percentage in a season to (i) our team strength estimates, (ii) each team's past cumulative point differential, and (iii) each team's past won-loss percentage. Within each sport, this is done by game number, which helps to account for league-level differences in season length. For purposes of using our team strength estimates, we took the mean posterior draw for each team in each week a particular contest was played. The lockout-shortened seasons in the NBA (2012) and NHL (2013) were dropped.

<<>>=
# load("data/tidy_betas.rda")
load("data/bigfour.rda")

bigfour <- bigfour %>% arrange(sport, Date)

min.day <- bigfour %>%
  group_by(sport, season) %>%
  summarise(min.day = min(gameDate), max.day = max(gameDate))

bigfour1 <- bigfour %>%
  left_join(min.day) %>%
  mutate(day = as.Date(gameDate) - as.Date(min.day),
         days.left = as.Date(max.day) - as.Date(gameDate), 
         max.days = day + days.left, 
         percent = as.numeric(day)/as.numeric(max.days), 
         scorediff.vis = visitor_score - home_score, 
         scorediff.home = -1*scorediff.vis)


date.vis <- bigfour1 %>% 
  select(gameDate, day, visitor_team, season, home_win, sport, scorediff.vis) %>%
  rename(team = visitor_team, pdiff = scorediff.vis) %>%
  mutate(win = !home_win) %>%
  select(-home_win)

date.home <- bigfour1 %>% 
  select(gameDate, day, home_team, season, home_win, sport, scorediff.home) %>%
  rename(team = home_team, pdiff = scorediff.home) %>%
  mutate(win = home_win) %>%
  select(-home_win)

stack.game <- rbind(date.vis, date.home)
stack.game <- stack.game %>%
  arrange(sport, season, team, day) 

n.season <- data.frame(sport = c("nhl", "nba", "mlb", "nfl"), season.n = c(82, 82, 162, 16))

stack.game1 <- stack.game %>%
  group_by(season, team) %>%
  mutate(n.game = row_number(), cum.wins = cumsum(win), 
         win.p = cum.wins/n.game, percent.season = n.game/n(), 
         wins.final = sum(win), win.p.final = wins.final/n(), 
         win.p.left = (wins.final - cum.wins)/(n()-n.game), 
         cum.diff = cumsum(pdiff)) #%>%
  #filter(!(sport == "nba" & n.game > 20))

stack.game1 <- filter(stack.game1, !(season==2012&sport == "nba"),
                      !(season==2013 & sport == "nhl"))


####################################################
## Next step: consider comparing wins and losses vs. betas at predicting 
## end of regular season wins and losses
##########################

############ Correlation of current win percentage with remaining win percentage

func.sport2 <- function(sports, days){
  names.sport <- subset(stack.game1, sport == sports)  
  corr.grid <- expand.grid(day.season = 1:days, corr.day = NA)
  for (i in 1:days){
    day.sport <- subset(stack.game1, n.game == i & sport == sports)
    corr.grid[i, 2] <- cor(day.sport$win.p, day.sport$win.p.left, use = "pairwise.complete.obs")^2
  }
  return(corr.grid)
}

mlb <- func.sport2("mlb", 162)
nfl <- func.sport2("nfl", 16)
nba <- func.sport2("nba", 82)
nhl <- func.sport2("nhl", 82)


mlb$sport <- "mlb"; nba$sport <- "nba"; nhl$sport <- "nhl"; nfl$sport <- "nfl"
all.sport.winp.remains <- rbind(mlb, nba, nhl, nfl)



############ Correlation of current point differential with remaining win percentage

func.sport2 <- function(sports, days){
  names.sport <- subset(stack.game1, sport == sports)  
  corr.grid <- expand.grid(day.season = 1:days, corr.day = NA)
  for (i in 1:days){
    day.sport <- subset(stack.game1, n.game == i & sport == sports)
    corr.grid[i, 2] <- cor(day.sport$cum.diff, day.sport$win.p.left, use = "pairwise.complete.obs")^2
  }
  return(corr.grid)
}

mlb <- func.sport2("mlb", 162)
nfl <- func.sport2("nfl", 16)
nba <- func.sport2("nba", 82)
nhl <- func.sport2("nhl", 82)


mlb$sport <- "mlb"; nba$sport <- "nba"; nhl$sport <- "nhl"; nfl$sport <- "nfl"
all.sport.pdiff.remains <- rbind(mlb, nba, nhl, nfl)




############ Correlation of current team strength estimate with remaining win percentage
tidy_betas <- filter(tidy_betas, !(season==7&sport == "nba"),
                      !(season==8 & sport == "nhl"), !(season==2 & sport == "nfl"))

unique.weeks <- tidy_betas %>%
  rename(team = name) %>%
  mutate(time_val = time_val + 1, season = floor(time_val)) %>% 
  arrange(sport, season, team) %>%
  select(sport, season, team, week, beta)

min.day <- stack.game1 %>%
  group_by(season, sport) %>%
  summarise(min.day = min(gameDate))

stack.game2 <- stack.game1 %>%
  left_join(min.day) %>%
  mutate(day = as.Date(gameDate) - as.Date(min.day), week = as.numeric(floor(day/7)+1)) %>%
  left_join(unique.weeks)


func.sport3 <- function(sports, week){
  names.sport <- subset(stack.game2, sport == sports)  
  corr.grid <- expand.grid(day.season = 1:week, corr.day = NA)
  for (i in 1:week){
    day.sport <- subset(stack.game2, n.game == i & sport == sports)
    corr.grid[i, 2] <- cor(day.sport$beta, day.sport$win.p.left, 
                           use = "pairwise.complete.obs")^2
  }
  return(corr.grid)
}

mlb <- func.sport3("mlb", 162)
nfl <- func.sport3("nfl", 16)
nba <- func.sport3("nba", 82)
nhl <- func.sport3("nhl", 82)


mlb$sport <- "mlb"; nba$sport <- "nba"; nhl$sport <- "nhl"; nfl$sport <- "nfl"


all.sport.beta.remains <- rbind(mlb, nba, nhl, nfl)
all.sport.beta.remains$type <- "betas"
all.sport.winp.remains$type <- "winp"
all.sport.pdiff.remains$type <- "pdiff"

all.sport.both <- rbind(all.sport.beta.remains, all.sport.winp.remains, all.sport.pdiff.remains)



gg.r2 <- ggplot(all.sport.both, aes(day.season, corr.day, lty = type)) +
  geom_step() + scale_y_continuous(labels = scales::percent, "", lim = c(0, 1)) + 
  scale_x_continuous("Game of season") +
  scale_linetype_manual(labels = c("Our estimates", "Past point differential", "Past win %"), 
                        values = c(1, 2, 3), "Type") +
  facet_wrap(~toupper(sport), scales = "free")  + 
  labs(title = "Coefficient of determination with year end win %") 
@

<<R2, fig.height = 4, fig.width = 6, fig.cap="Coefficient of determination with future in-season win percentage.">>=
gg.r2
@

Across each sport, our estimates of team strength consistently outperform past team win percentage and point differential as far as predicting future win percentage. This gap is most pronounced earlier in each season, which is not surprising given the fluctuations in won-loss percentage and point differential in a small number of games, as well as the fact that our model borrows information from the future when assessing team talent. Differences in predictive accuracy remain throughout most of the regular season in the NHL, MLB, and the NFL, while by the NBA's mid-season, won-loss ratio and point differential are similar to our estimates of team strength in assessing future performance. Altogether, results suggest that across seasons and sports, team strength estimates from our state-space model more completely judge team talent than won-loss percentage and point differential. 

\subsection{How often does the best team win?  A better measure of league parity}

We conclude by returning to one of our initial questions regarding the inherent randomness of game outcomes. While sportsbook odds can approximate the probability of each team winning, these odds are only provided for scheduled games. As a result, any between-league comparisons using sports-book odds alone would be contingent upon each league's schedule. 

To better assess the equivalence of all teams in each league, we consider the likelihood that, given any pair of teams chosen at random, the better team won. For our purposes, we define the $better$ team to be the one, a priori, with a better probability of winning that given game, which is a function of both team strength and inherent game level error. If the better team in a randomly chosen match-up wins more often, it would correspond to a sport with less inherent randomness. Using our posterior draws, we approximate the distribution of game-level probabilities between two randomly chosen teams using the following steps.

Given sport $q$ with season length $k^{\star}_{q}$, number of seasons $s^{\star}_{q}$, and number of teams $t_{q}$, 

\begin{enumerate}
\item Draw season $\tilde{s}$ from $\left\{1, \ldots, s^{\star}_{q} \right \}$
\item Draw week $\tilde{k}$ from $\left\{1, \ldots , k^{\star}_{q} \right \}$
\item Draw teams $\tilde{i}$ and $\tilde{j}$ from $\left \{1, \ldots , t_{q} \right \}$ without replacement.
\item Sample one posterior draw of team strength for $\tilde{i}$ and $\tilde{j}$, $\tilde{\theta}_{(q,\tilde{s},\tilde{k}) \tilde{i}}$ and $\tilde{\theta}_{(q,\tilde{s},\tilde{k}) \tilde{j}}$, respectively, from the posterior distributions of $\tilde{i}$ and $\tilde{j}$'s team strength estimates during season $\tilde{s}$ at week $\tilde{k}$
\item Sample one posterior draw of the HA, $\tilde{\alpha}_{q_0}$, from the posterior distribution of $\alpha_{q_0}$
\item Sample one posterior draw of game-level error, $\tilde{\tau}_{q, game}$, from the posterior distribution of $\tau_{q, game}$, and assign the error to be positive with 50\% probability and negative with 50\% probability. 
\item Impute simulated log-odds of the better team winning between $\tilde{i}$ beating $\tilde{j}$, $\text{logit}(p_{(q,\tilde{s},\tilde{k}) \tilde{i}\tilde{j}}) = \tilde{\alpha}_{q_0} + |\tilde{\theta}_{(q,\tilde{s},\tilde{k}) \tilde{i}} - \tilde{\theta}_{(q,\tilde{s},\tilde{k}) \tilde{j}} + \tilde{\tau}_{q, game}|$, where the $better$ team's log-odds are based on $\tilde{\theta}_{(q,\tilde{s},\tilde{k}) \tilde{i}}$, $\tilde{\theta}_{(q,\tilde{s},\tilde{k}) \tilde{j}}$, and $\tilde{\tau}_{q, game}$. The home advantage is always assigned to team considered to be better for any given contest.
\item Transform $\text{logit}(\tilde{p}_{(q,\tilde{s},\tilde{k}) \tilde{i}\tilde{j}})$ into probability form to obtain a simulated estimate, $\tilde{p}_{q, sim}$, where  $\tilde{p}_{q, sim} = \tilde{p}_{(q,\tilde{s},\tilde{k}) \tilde{i}\tilde{j}}$
\item Repeat the above steps $n_{sim}$ times to obtain $\mathbf{\tilde{p}_{q}} = \left\{\tilde{p}_{q, 1}, \ldots \tilde{p}_{q, n_{sim}}\right\}$.
\end{enumerate}

The steps above were repeated for each $q$ with $n_{sim} = 1000$. Additionally, to remove the effect of each league's HA on simulated probabilities, we repeated the process using by fixing $\tilde{\alpha}_{q_0} = 0$ for each league, reflecting the probability that would have been given for the game being played at a neutral site.

Figure \ref{fig:BestWin} shows the cumulative distribution functions (CDFs) for each set of probabilities in each league. 

\begin{figure}[h]
\includegraphics{figure/BestWin.pdf}
\caption{Cumulative Distribution Function (CDF) of 1000 simulated game-level probabilities in each league, for both neutral site and home games, with the better team (on average) used as the reference and given the home advantage.\label{fig:BestWin}}
\end{figure}

The median probability of the best team winning a neutral site game is highest in the NBA (67\%), followed in order by the NFL (65\%), NHL (57\%), and MLB (56\%). Nearly every simulated netural site MLB and NHL game played at neutral site is less than a 3:1 proposition with respect to the best team winning (75\%). Meanwhile, roughly 30\% of NBA and 23\% of NFL neutral site match-ups are greater than this 3:1 threshold. 

Factoring in each league's home advantage works to exaggerate league-level differences. When the best team plays at home in the NBA, that squad is always favored to win at least 60\% of the time, with the middle 50\% of games ranging from a 70\% probability to an 85\% probability. Meanwhile, even with a home advantage, it is rare that the best MLB team is $ever$ given a 70\% probability of winning, with the middle 50\% of games ranging from 57\% to 63\%. 

\mike{This is still a work in progress. Think the best idea is to tie into area under curve. Highest area = 1 = complete parity, lowest area = 0 = no parity. R code for trapezoid area here

http://stats.stackexchange.com/questions/145566/how-to-calculate-area-under-the-curve-auc-or-the-c-statistic-by-hand}

Finally, we use the CDFs displayed above to quantify the proximity of each league's game-level probabilities to coin flips by estimating the approximate area under each curve Let $Parity_q$ be our parity measure, such that

$$Parity_q = 2*\int_{0.5}^1 P(\mathbf{\tilde{p}_{q}} \leq x) dx$$,

where we multiply by 2 in order to scale so that $0 \leq Parity_q \leq 1$, where 1 represents complete parity (every game a coin flip) and 0 represents no parity (every game outcome pre-determined) \mike{Tie to AUC?}

For games with no home advantage, $Parity_{MLB} = 86\%$, followed by the NHL (83\%), NFL (68\%), and NBA (64\%). When the best team has a home advantage, parity is again the greatet in the MLB (79\%), followed by the NHL (73\%), NFL (54\%), and NBA (46\%). Taken wholly, this suggests that when the best team is playing at home, the NBA is closer to a world where every game outcome is pre-determined than to one where every game outcome is a coin flip. Meanwhile, even when giving the best team a HA, MLB game outcomes remain lightly-weighted coin flips. 


\section{Conclusion}

Using a modified Bayesian state-space model, we estimate both time-varying team strength and league-level variance parameters in order to better explain the underlying randomness in the four major North American professional sporting leagues, the NBA, NFL, NHL, and MLB. 

Our first finding relates to the relative equivalence of the four leagues. At a single point in time, team strength estimates diverge substantially more in the NBA and NFL than in the NHL and MLB. In the latter two leagues, contests between two randomly chosen teams are closer to to a coin-flip, with each team has a reasonable shot at winning. 

Our second set of findings relates to the autoregressive nature of team strengths. Within a season, posterior estimates suggest that teams in each of the NBA (largest reversion), NFL, and NHL tend to revert towards the league average in the long term on a week-to-week basis, while trends of team strength in MLB are indistinguishable from a random walk. On a season-to-season basis, NHL teams exhibit the largest reversion (nearly 50\%) towards the league average, with the other three leagues falling somewhere between roughly 25\% and 40\%. 

Our next finding relates to the relative equivalence of the home advantage in each league, with the NBA well ahead of the pack, showing, on average, a \Sexpr{round(leagues$mean.sport[2], 3)} increase on the log-odds of a home win (which corresponds to a win probability of \Sexpr{100*round(exp(leagues$mean.sport[2])/(1+exp(leagues$mean.sport[2])), 3)}\% against a like-caliber opponent). We also show that the home advantage varies most significantly between arenas within each of the NBA and the NHL. In the NBA, for example, the league's best team home advantage is worth a few wins per year, in expectation, over the league's worst home advantage. 

Finally, we identify that incorporating information from betting markets can help to more accurately gauge the caliber of each league's teams, as shown by more accurate forecasts of future team performance. Unlike wins and losses or point differential, our estimates of team strength account for league characteristics such as unbalanced schedules and season length. We conclude by using these team strength draws to propose a parity metric that can compare team equivalence without being impacted by league-level characteristics like unbalanced schedules. 

Opportunities to extend our model are plentiful. One approach would use our team strength estimates to examine how each league's scheduling quirks impact resulting won-loss standings. As an example, what is the impact of the NFL using an unbalanced schedule? A second task would link our estimates of team strength to performance in the postseason. How likely is it for the best team to win each league's title? Alternatively, how likely is it for the best team in each league to win a 7-game series? Finally, one could use time-varying estimates of team strength to consider the existence of tanking, in which teams---in order to secure a better draft position---are better off losing games later in the season. While this has been demonstrated in basketball using betting market data \citep{soebbing2013gamblers}, it would also be worth looking at tanking in other leagues, or if team interest in tanking corresponds to the perceived talent available in the upcoming draft.

To maintain consistency with the NFL's calendar, we considered time on a weekly basis. More refined approaches may be appropriate in other sports. As an example, investigation into starting pitchers---who change daily---in baseball could lead to novel findings. Additionally, another model specification could consider the possibility that time-varying estimates of team strength follow something other than an autoregressive structure. One alternative specification, for example, is a stochastic volatility process \citep{glickman2001dynamic}. In this respect, our model can be looked at as a starting point for those looking to dig deeper in any sport witout losing an ability to make cross-league comparisons. 

\mike{Does this paragraph fit? I like it but can't place it.}
Understanding this underlying randomness and the proper evaluation of team talent is crucial to decision makers in these leagues. At critical moments in a team's evolution, such as the trade deadline, free agency, or in the choice to fire a coach, we recommend that team officials look past wins and losses to better understand team strength in the context of their league. As one easy example, it is insufficient to evaluate a baseball or hockey team based on their performance in the postseason alone, given that so many of those contests are near 50-50 outcomes. 


\mike{To do before publication
i) unneeded files in Github
ii) parameter names in most files don't match those in document}



\section{Appendix}



\begin{figure}[h]
\includegraphics[angle=90]{figure/MLBtrace.pdf}
\caption{Trace plots of MLB parameters\label{fig:MLBtrace}}
\end{figure}

\newpage

\begin{figure}[h]
\includegraphics[angle=90]{figure/NBAtrace.pdf}
\caption{Trace plots of NBA parameters\label{fig:NBAtrace}}
\end{figure}

\newpage


\begin{figure}[h]
\includegraphics[angle=90]{figure/NFLtrace.pdf}
\caption{Trace plots of NFL parameters\label{fig:NFLtrace}}
\end{figure}

\newpage 

\begin{figure}[h]
\includegraphics[angle=90]{figure/NHLtrace.pdf}
\caption{Trace plots of NHL parameters\label{fig:NHLtrace}}
\end{figure}

\newpage


<<spaghetti-mlb, fig.height=11, fig.width = 8, fig.cap="Team strength coefficients over time for Major League Baseball.">>=
# mlb.team
spag_sport("MLB")
@

<<spaghetti-nba, fig.height=11, fig.width = 8, fig.cap="Team strength coefficients over time for the National Basketball Association.">>=
spag_sport("NBA")
@

<<spaghetti-nfl, fig.height=11, fig.width = 8, fig.cap="Team strength coefficients over time for the National Football League.">>=
spag_sport("NFL")
@

<<spaghetti-nhl, fig.height=11, fig.width = 8, fig.cap="Team strength coefficients over time for the National Hockey League.">>=
spag_sport("NHL")
@


\bibliographystyle{asa}
\bibliography{refs}

\newpage

\phantom{xxxx}

\vspace{3cm}

\begin{center}
{\Large  {\bf Supplementary Materials for \\ 

\vspace{2cm}

``A unified approach to understanding randomness in sport"}}
\end{center}

\newpage

%\input{appendix}
%\input{prelim}
%\input{model}
%\input{results}




%\input{summary}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\input{appendix}



\end{document}
